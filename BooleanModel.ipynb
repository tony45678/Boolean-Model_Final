{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BooleanModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ZfBYdjdruEyptZPo7t4AuA9pVfjxrNLa",
      "authorship_tag": "ABX9TyPr7dNr1fmiKK0Y+nmtwJYc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony45678/Boolean-Model_Final/blob/master/BooleanModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmaCa3q3nX3y",
        "colab_type": "text"
      },
      "source": [
        "# **Boolean Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLPpUE_nLgC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Import Necessary Libaries**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fimW_ocXJo8d",
        "colab_type": "code",
        "outputId": "1cba3fe6-fb2b-420d-beb2-a7777095d23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import nltk\n",
        "import csv\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_7Ssw-kJ1uV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "* **Import Text Files and save it to documents.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkofld8SJtVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = {}\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    file=str(x)+\".txt\"\n",
        "    D[x]=open(file).read()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT54NI8jMAIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scripts=\"\"\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    scripts=scripts+\" \\n\"+D[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MeUBy7jYwB1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "* **Tokenize the Texts.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5n20tUNOgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_text=nltk.word_tokenize(scripts)\n",
        "real_text=list(set(real_text))  #Tokenized words \n",
        "#print(len(real_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9zZGbiVNR1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_charactersymbols=str.maketrans(\"\", \"\", \"~`!@#$%^&*(),.\") #Remove character Symbols\n",
        "real_text=[x.translate(remove_charactersymbols) for x in real_text]\n",
        "#print(len(real_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu8szcqHcc2j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Remove Stop Words**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CD-AUt4NtPP",
        "colab_type": "code",
        "outputId": "279a1b2a-442f-40f9-d1e0-bc16082eb894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Import stopword.txt\n",
        "stopword=open(\"stopword.txt\").read()\n",
        "stopword=nltk.word_tokenize(stopword)\n",
        "\n",
        "real_text=set(real_text)-set(stopword) #Remove stop words\n",
        "real_text=list(real_text)\n",
        "#print(len(real_text))"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5ENXfoyRx4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Sorting**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SENElGLQN8SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sort the text that have been tokenize.\n",
        "real_text=sorted(real_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz9COOwgyYLD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Whole Script Tokenization & Sorting**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXiq3vGvOH6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Whole script Tokenization\n",
        "real_script={}\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    real_script[x]=nltk.word_tokenize(D[x])\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    real_script[x]=set(real_script[x])\n",
        "    real_script[x]=list(real_script[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i45iqnG3OTRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Remove character Symbols from final script\n",
        "remove_charactersymbols=str.maketrans(\"\", \"\", \"~`!@#$%^&*(),.\")\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    real_script[x]=[y.translate(remove_charactersymbols) for y in real_script[x]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-z-NorKOX6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Final sciprt sorting\n",
        "for x in range(20):\n",
        "    x=x+1\n",
        "    real_script[x]=sorted(real_script[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qREDqJwAyzzo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Lists**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMP6bKT-OiTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lists = {}\n",
        "I=[]\n",
        "count = 0\n",
        "\n",
        "for x in range(len(real_text)):\n",
        "    I=[]\n",
        "    for y in range(20):\n",
        "        y = y+1\n",
        "\n",
        "        if real_text[x] in real_script[y]:\n",
        "            I.append(y)\n",
        "\n",
        "    lists[x]=I              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-El66Dgmy5gz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Making Dictionary**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P3lNIM1O3oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict={}\n",
        "for x in range(len(real_text)):\n",
        "    dict.update({real_text[x]:lists[x]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Oh3tavPAPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('dict.csv', 'w',newline=\"\") as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in dict.items():\n",
        "        writer.writerow([key, value])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW_FjIDtzBI1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Input Query**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jO3F0kjPGH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input_words =\"twat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bee-yLLPJCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4dde48b2-d4cc-4262-e42f-89136f4c95fe"
      },
      "source": [
        "Iw=nltk.word_tokenize(Input_words)\n",
        "print(Iw)\n",
        "#Remove Symbols\n",
        "remove_symbols=str.maketrans(\"\", \"\", \"~`!@#$%^&*(),.\")\n",
        "Iw=[x.translate(remove_symbols) for x in Iw]"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['twat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1W--SxHI3gW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **Output**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnPvlY34PNzG",
        "colab_type": "code",
        "outputId": "d8b8211a-7825-4109-be58-c5c15af22fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "ans=[]\n",
        "temp=[]\n",
        "if len(Iw) == 1:\n",
        "    try:\n",
        "        ans=dict[Iw[0]]\n",
        "    except KeyError:\n",
        "        print(\"Key Error\")\n",
        "    if not ans:\n",
        "        printString = \"Result for the Query : \" + Iw[0]\n",
        "        print (\"No Match\")\n",
        "\n",
        "    else:\n",
        "        print (\"Result for the Query : \" + Iw[0])\n",
        "        print (\"Total documents : \" + str(len(ans)))\n",
        "        print(\"Documents: \")\n",
        "        print(ans)\n",
        "                \n",
        "                \n",
        "else:\n",
        "    x=0\n",
        "    for i in range(len(Iw)):\n",
        "        \n",
        "        if (x>(len(Iw))+i-3):\n",
        "            break   \n",
        "        if (Iw[i+1]==\"and\"):                                                            #AND\n",
        "            try:\n",
        "                temp=set(dict[qt[i]]).intersection(set(dict[Iw[i+2]]))\n",
        "                ans.append(temp)\n",
        "            except KeyError:\n",
        "                print(\"Key Error\")\n",
        "                ans.append([])        \n",
        "\n",
        "        elif (Iw[i+1]==\"or\"):                                                            #OR\n",
        "            try:\n",
        "                temp=set(dict[qt[i]]).union(set(dict[Iw[i+2]]))\n",
        "                ans.append(temp)\n",
        "            except KeyError:\n",
        "                print(\"Error\")\n",
        "                ans.append([])\n",
        "            \n",
        "        elif (Iw[i+1]==\"not\"):                                                            #NOT\n",
        "            try:\n",
        "                ans.append(set(dict[Iw[i]]).difference(set(dict[Iw[i+2]])))\n",
        "            except KeyError:\n",
        "                print(\"Error\")\n",
        "                ans.append([])\n",
        "        x=x+2\n",
        "            \n",
        "        \n",
        "    print (\"Result for the Query : \")\n",
        "    print(Input_words)\n",
        "    print (\"Total documents : \" + str(len(ans[-1])))\n",
        "    print(\"Documents: \")\n",
        "    print(ans[-1])"
      ],
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result for the Query : twat\n",
            "Total documents : 1\n",
            "Documents: \n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}