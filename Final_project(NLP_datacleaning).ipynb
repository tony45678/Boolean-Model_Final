{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project(NLP_datacleaning).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOWoi5Qw2c9i9gJyxIU5Pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyyoon123/Boolean-Model_Final/blob/master/Final_project(NLP_datacleaning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QoUJlr6rqGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import csv\n",
        "import pandas as pd\n",
        "import pickle\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjWeJez1AE00",
        "colab_type": "text"
      },
      "source": [
        "**Import Text Files and save it to documents.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdmKEKvssn5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = {}\n",
        "for x  in range(11):\n",
        "    x=x+1\n",
        "    file=str(x)+\".txt\"\n",
        "    D[x]=open(file).read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1PARwsos_Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scripts=\"\"\n",
        "for x in range(11):\n",
        "    x=x+1\n",
        "    scripts=scripts+\" \\n\"+D[x]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOD707zYE44G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZHmRcTtARax",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize the Texts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcKABQIE_C9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next(iter(D.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcDsv3bDFS5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next(iter(D.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-dFohsdFiJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_text(list_of_text):\n",
        "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
        "    combined_text = ' '.join(list_of_text)\n",
        "    return combined_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scw6ya-9FljP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_combined = {key: [combine_text(value)] for (key, value) in D.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoDaswSEFxjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('max_colwidth',150)\n",
        "D_df = pd.DataFrame.from_dict(D_combined).transpose()\n",
        "D_df.columns = ['script']\n",
        "D_df = D_df.sort_index()\n",
        "D_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EJs38CKGOPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_df.script.loc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BL6JieTJ0ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text_round1(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text_round1(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1axSEAsoJ6i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean = pd.DataFrame(D_df.script.apply(round1))\n",
        "D_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-OQ7WyYkuLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean.script.loc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhpoGoyBKFyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text_round2(text):\n",
        "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    return text\n",
        "\n",
        "round2 = lambda x: clean_text_round2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwjnLBAKIJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean = pd.DataFrame(D_clean.script.apply(round2))\n",
        "D_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8YsvabNk1OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean.script.loc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5NpBRROKO2y",
        "colab_type": "text"
      },
      "source": [
        "# **Organize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4VxZAqiKNHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW9etMksNBiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean.to_pickle(\"corpus.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XwECr0iNJBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwpcPSP8NxFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", stop_words='english', ngram_range=(2,2), analyzer='word')\n",
        "D_cv = cv.fit_transform(D_clean.script)\n",
        "D_dtm  = pd.DataFrame(D_cv.toarray(), columns=cv.get_feature_names())\n",
        "D_dtm.index = D_clean.index\n",
        "D_dtm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnZUdtdSn_XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_dtm.to_pickle(\"dtm.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7pbhsumoC0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_clean.to_pickle('D_clean.pkl')\n",
        "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}